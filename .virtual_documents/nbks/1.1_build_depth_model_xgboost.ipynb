import numpy as np
import os, sys
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid1 import make_axes_locatable
import seaborn as sns
from collections import Counter
from tqdm.auto import tqdm, trange
from sklearn.preprocessing import MinMaxScaler
import re
import concurrent.futures
from sklearn.metrics import silhouette_score
from scipy.stats import pearsonr
import copy
import pickle
import xgboost as xgb
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, DistributedSampler
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
from torchvision import transforms
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from kmeans_pytorch import kmeans

from sdv.metadata import SingleTableMetadata
from sdv.evaluation.single_table import evaluate_quality
from sdv.single_table import CTGANSynthesizer
from sdv.sampling import Condition
from sdv.evaluation.single_table import get_column_plot

import dask.dataframe as dpd
import dask_geopandas as dgpd
from dask.diagnostics import ProgressBar
from dask.distributed import Client

import warnings
warnings.filterwarnings('ignore')

import gc
gc.collect()

np.random.seed(0)


client = Client(n_workers=80) #192 totally


client.close()


print(torch.__version__, torch.cuda.is_available())
torch.cuda.set_device(0)


if torch.cuda.device_count() >= 1:
    print(f"We have {torch.cuda.device_count()} GPUs!")


# Plot geo map
def plot_map(gdf, col, vmin=0, vmax=300, figsize=(8, 6), dpi=200, notes='', to_path='', dots=[], title=True, s=1):
    plt.clf()
    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="5%", pad=0.1)

    # Plot without specifying legend_kwds
    try:
        gdf.plot(ax=ax, column=col, cmap='coolwarm', vmin=vmin, vmax=vmax, cax=cax, s=s)
    except:
        gdf.plot(ax=ax, column=col, cmap='coolwarm', vmin=vmin, vmax=vmax, cax=cax)
    if dots:
        for dot in dots:
            gdf.loc[dot:dot].plot(ax=ax, linewidth=1, color='black', alpha=0.5)
            ax.text(gdf.loc[dot, 'x'], gdf.loc[dot, 'y'], str(dot), fontsize=12)

    # Create colorbar with custom font size
    sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=vmin, vmax=vmax))
    sm.set_array([])
    cbar = fig.colorbar(sm, cax=cax, 
#                         label=col.upper(), 
                        shrink=.5)
#     cbar.ax.tick_params(labelsize=20)  # Set the font size for the colorbar
#     bd_gdf.boundary.plot(ax=ax, linewidth=1, color='k')
    # Change tick fontsize
    ax.tick_params(axis='both', which='major', labelsize=20)
    ax.set_xticks([])
    ax.set_yticks([])
#     ax.scatter(gdf['x'], gdf['y'], s=1, c='k')
    
    # Change color bar fontsize
#     cbar.set_label(col.upper(), fontsize=20)
    if title:
        ax.set_title(f'{col.upper()}')
#     if not os.path.exists(f'plots/test/{notes}'):
#         os.mkdir(f'plots/test/{notes}')
#     fig.savefig(f'plots/test/{notes}/{col}.png')
    if to_path:
        fig.savefig(f'{to_path}')


coord_gdf = gpd.read_file('../src/coord/coord_gdf.shp')
coord_gdf = coord_gdf.drop(columns=['cell_rmse1', 'cell_r21', 'cell_rmse2', 'cell_r22', 'depth'])
coord_gdf


watershed_dict = coord_gdf.drop_duplicates(subset='HUC12').set_index('HUC12')['region'].to_dict()
watershed_dict





scaler = MinMaxScaler()
xy_scaled = scaler.fit_transform(coord_gdf[['x', 'y']])

def load_and_scale(file_path, scale=False):
    df = pd.read_parquet(file_path)[['x', 'y', 'channel', 'ter', 'cumu_rain', 'peak_int', 'duration', 'depth']]
    if scale:
        df[['x', 'y']] = xy_scaled
    return df

file_paths = [f'../src/tables/data{i}.parquet' for i in range(1, len([f for f in os.listdir('../src/tables') if f.endswith('.parquet')]) + 1)]
events = [load_and_scale(file) for file in file_paths]
with ProgressBar():
    result = dpd.concat(events, axis=0)
events_df = result.compute()


events_df


feature_cols = ['channel', 'ter', 'cumu_rain', 'peak_int', 'duration']
features = events_df[feature_cols].values
targets = events_df[['depth']].values

X_train, X_temp, y_train, y_temp = train_test_split(
    features, targets, test_size=0.4, random_state=0)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, y_temp, test_size=0.5, random_state=0)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)


dtrain = xgb.DMatrix(X_train_scaled, y_train)
dval = xgb.DMatrix(X_val_scaled, y_val)
dtest = xgb.DMatrix(X_test_scaled, y_test)


def loss_metric_eval(y_pred, dtrue, loss_str):
    y_pred = np.maximum(0, y_pred)
    loss_str = loss_str.lower()
    y_true = dtrue.get_label()
    if loss_str == "rmsle":
        return loss_str, np.sqrt(np.mean((np.log(y_true+1) - np.log(y_pred+1))**2))
    elif loss_str == "mae":
        return loss_str, np.mean(np.abs(y_true - y_pred))
    else:
        return 'rmse', np.sqrt(np.mean((y_true - y_pred)**2))


params = {
    'tree_method': 'gpu_hist',
    'subsample': 0.9,
    'n_estimators': 1000,
    'min_child_weight': 2,
    'max_depth': 8,
    'learning_rate': 0.005,
    'gamma': 0.1,
    'colsample_bytree': 0.5,
    'colsample_bylevel': 0.85,
    "objective": "reg:squarederror",
    "max_bin": 2048,
    "eval_metric": "rmse",
    "gpu_id": 0,
    "alpha": 1,
    "lambda": 10
}


best_checkpoint = os.path.join('../checkpoints/depth', f'XGBoost.mod')
train_history = []
val_history = []
test_history_100 = []


def loss_metric_eval(y_pred, dtrue, loss_str):
    y_pred = np.maximum(0, y_pred)
    loss_str = loss_str.lower()
    y_true = dtrue.get_label()
    if loss_str == "rmsle":
        return loss_str, np.sqrt(np.mean((np.log(y_true+1) - np.log(y_pred+1))**2))
    elif loss_str == "mae":
        return loss_str, np.mean(np.abs(y_true - y_pred))
    else:
        return 'rmse', np.sqrt(np.mean((y_true - y_pred)**2))


class CustomEvaluationCallback(xgb.callback.TrainingCallback):
    def __init__(self, dtest, eval_every=100):
        self.dtest = dtest
        self.eval_every = eval_every
        self.best_loss = float("inf")
        self.best_epoch = 0

    def after_iteration(self, model, epoch, evals_log):
        global best_epoch
        # Record the training RMSE
        train_loss = evals_log['train']['rmse'][-1]
        train_history.append(train_loss)

        # Evaluate on the validation set
        val_loss = evals_log['val']['rmse'][-1]
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            model.save_model(best_checkpoint)
            self.best_epoch = epoch
#             print(f'Epoch {epoch} {loss_metric}={val_loss:.3f} saved better checkpoint to {best_checkpoint}')
        val_history.append(val_loss)

        if epoch % self.eval_every == 0 and epoch > 0:
            test_preds = np.maximum(0, model.predict(self.dtest))
            _, test_loss = loss_metric_eval(test_preds, self.dtest, 'rmse')
            test_history_100.append(test_loss)
        return False


custom_eval_cb = CustomEvaluationCallback(dtest)
feval_wrapper = lambda y_pred, dtrue: loss_metric_eval(y_pred, dtrue, 'rmse')


model = xgb.train(
        params,
        dtrain,
        num_boost_round=5000,
        evals=[(dtrain, "train"), (dval, "val")],
        feval=feval_wrapper,
        callbacks=[custom_eval_cb],
    )


test_history_100


params = {
    **params,
    'n_jobs': 80
}


model = xgb.XGBRegressor(**params)
model.load_model(best_checkpoint)


y_preds = np.maximum(0, model.predict(X_test_scaled))
y_trues = y_test.reshape(-1,)


def calc_rmse(y_trues, y_preds, indices=[]):
    if len(indices) > 0:
        y_trues = y_trues[indices]
        y_preds = y_preds[indices]
    return np.round(np.sqrt(np.mean((y_preds[:] - y_trues[:]) ** 2)), 4)

def calc_r2(y_trues, y_preds, indices=[]):
    if len(indices) > 0:
        y_trues = y_trues[indices]
        y_preds = y_preds[indices]
    return np.round(1 - (np.sum((y_preds - y_trues)**2))/(np.sum((y_trues - np.mean(y_trues))**2)), 4)


test_rmse = calc_rmse(y_trues, y_preds)
test_r2 = calc_r2(y_trues, y_preds)
test_result_dict = {
    'rmse': test_rmse,
    'r2': test_r2,
}


channel_indices = np.where(scaler.inverse_transform(X_test_scaled)[:, 0] == 1)[0]
non_channel_indices = np.where(scaler.inverse_transform(X_test_scaled)[:, 0] == 0)[0]


channel_rmse = calc_rmse(y_trues, y_preds, channel_indices)
channel_r2 = calc_r2(y_trues, y_preds, channel_indices)
non_channel_rmse = calc_rmse(y_trues, y_preds, non_channel_indices)
non_channel_r2 = calc_r2(y_trues, y_preds, non_channel_indices)
test_result_dict['channel_rmse'] = channel_rmse
test_result_dict['channel_r2'] = channel_r2
test_result_dict['non_channel_rmse'] = non_channel_rmse
test_result_dict['non_channel_r2'] = non_channel_r2


test_result_dict



