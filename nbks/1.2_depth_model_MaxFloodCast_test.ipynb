{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/l/lipai.huang/GAN_simulated_events/se_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm.auto import tqdm, trange\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import re\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.stats import pearsonr\n",
    "import copy\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.single_table import CTGANSynthesizer\n",
    "from sdv.sampling import Condition\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "\n",
    "import dask.dataframe as dpd\n",
    "import dask_geopandas as dgpd\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(n_workers=80) #192 totally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118 True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, torch.cuda.is_available())\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1 GPUs!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() >= 1:\n",
    "    print(f\"We have {torch.cuda.device_count()} GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot geo map\n",
    "def plot_map(gdf, col, vmin=0, vmax=300, figsize=(8, 6), dpi=200, notes='', to_path='', dots=[], title=True, s=1):\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "\n",
    "    # Plot without specifying legend_kwds\n",
    "    try:\n",
    "        gdf.plot(ax=ax, column=col, cmap='coolwarm', vmin=vmin, vmax=vmax, cax=cax, s=s)\n",
    "    except:\n",
    "        gdf.plot(ax=ax, column=col, cmap='coolwarm', vmin=vmin, vmax=vmax, cax=cax)\n",
    "    if dots:\n",
    "        for dot in dots:\n",
    "            gdf.loc[dot:dot].plot(ax=ax, linewidth=1, color='black', alpha=0.5)\n",
    "            ax.text(gdf.loc[dot, 'x'], gdf.loc[dot, 'y'], str(dot), fontsize=12)\n",
    "\n",
    "    # Create colorbar with custom font size\n",
    "    sm = plt.cm.ScalarMappable(cmap='coolwarm', norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, cax=cax, \n",
    "#                         label=col.upper(), \n",
    "                        shrink=.5)\n",
    "#     cbar.ax.tick_params(labelsize=20)  # Set the font size for the colorbar\n",
    "#     bd_gdf.boundary.plot(ax=ax, linewidth=1, color='k')\n",
    "    # Change tick fontsize\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "#     ax.scatter(gdf['x'], gdf['y'], s=1, c='k')\n",
    "    \n",
    "    # Change color bar fontsize\n",
    "#     cbar.set_label(col.upper(), fontsize=20)\n",
    "    if title:\n",
    "        ax.set_title(f'{col.upper()}')\n",
    "#     if not os.path.exists(f'plots/test/{notes}'):\n",
    "#         os.mkdir(f'plots/test/{notes}')\n",
    "#     fig.savefig(f'plots/test/{notes}/{col}.png')\n",
    "    if to_path:\n",
    "        fig.savefig(f'{to_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>ter</th>\n",
       "      <th>HUC12</th>\n",
       "      <th>region</th>\n",
       "      <th>channel</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.933766e+06</td>\n",
       "      <td>1.396557e+07</td>\n",
       "      <td>301.388702</td>\n",
       "      <td>Cypress Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2934366.000 13964974.635, 2933003.17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.934966e+06</td>\n",
       "      <td>1.396557e+07</td>\n",
       "      <td>301.594696</td>\n",
       "      <td>Cypress Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2934366.000 13967369.160, 2934380.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.933766e+06</td>\n",
       "      <td>1.396437e+07</td>\n",
       "      <td>294.629181</td>\n",
       "      <td>Cypress Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2934366.000 13964974.635, 2934366.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.934966e+06</td>\n",
       "      <td>1.396437e+07</td>\n",
       "      <td>298.529877</td>\n",
       "      <td>Cypress Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2935566.000 13963774.635, 2934366.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.936166e+06</td>\n",
       "      <td>1.396437e+07</td>\n",
       "      <td>294.815002</td>\n",
       "      <td>Cypress Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((2936766.000 13963774.635, 2935566.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>3.039069e+06</td>\n",
       "      <td>1.385008e+07</td>\n",
       "      <td>54.643570</td>\n",
       "      <td>Whiteoak Bayou-Buffalo Bayou</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((3039427.707 13849492.726, 3038745.86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>3.039053e+06</td>\n",
       "      <td>1.385088e+07</td>\n",
       "      <td>59.625050</td>\n",
       "      <td>Addicks Reservoir</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((3039399.212 13851153.541, 3039405.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26298</th>\n",
       "      <td>3.038396e+06</td>\n",
       "      <td>1.385006e+07</td>\n",
       "      <td>60.055576</td>\n",
       "      <td>Whiteoak Bayou-Buffalo Bayou</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((3038723.769 13850469.724, 3038724.68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>3.038392e+06</td>\n",
       "      <td>1.385087e+07</td>\n",
       "      <td>59.625050</td>\n",
       "      <td>Addicks Reservoir</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((3038721.900 13851266.014, 3038723.76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>3.037707e+06</td>\n",
       "      <td>1.385085e+07</td>\n",
       "      <td>72.228638</td>\n",
       "      <td>Addicks Reservoir</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>POLYGON ((3037766.475 13851439.564, 3038034.75...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26301 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y         ter                         HUC12  \\\n",
       "0      2.933766e+06  1.396557e+07  301.388702                 Cypress Creek   \n",
       "1      2.934966e+06  1.396557e+07  301.594696                 Cypress Creek   \n",
       "2      2.933766e+06  1.396437e+07  294.629181                 Cypress Creek   \n",
       "3      2.934966e+06  1.396437e+07  298.529877                 Cypress Creek   \n",
       "4      2.936166e+06  1.396437e+07  294.815002                 Cypress Creek   \n",
       "...             ...           ...         ...                           ...   \n",
       "26296  3.039069e+06  1.385008e+07   54.643570  Whiteoak Bayou-Buffalo Bayou   \n",
       "26297  3.039053e+06  1.385088e+07   59.625050             Addicks Reservoir   \n",
       "26298  3.038396e+06  1.385006e+07   60.055576  Whiteoak Bayou-Buffalo Bayou   \n",
       "26299  3.038392e+06  1.385087e+07   59.625050             Addicks Reservoir   \n",
       "26300  3.037707e+06  1.385085e+07   72.228638             Addicks Reservoir   \n",
       "\n",
       "       region  channel                                           geometry  \n",
       "0           0        0  POLYGON ((2934366.000 13964974.635, 2933003.17...  \n",
       "1           0        0  POLYGON ((2934366.000 13967369.160, 2934380.33...  \n",
       "2           0        0  POLYGON ((2934366.000 13964974.635, 2934366.00...  \n",
       "3           0        0  POLYGON ((2935566.000 13963774.635, 2934366.00...  \n",
       "4           0        0  POLYGON ((2936766.000 13963774.635, 2935566.00...  \n",
       "...       ...      ...                                                ...  \n",
       "26296       2        1  POLYGON ((3039427.707 13849492.726, 3038745.86...  \n",
       "26297       3        1  POLYGON ((3039399.212 13851153.541, 3039405.50...  \n",
       "26298       2        0  POLYGON ((3038723.769 13850469.724, 3038724.68...  \n",
       "26299       3        0  POLYGON ((3038721.900 13851266.014, 3038723.76...  \n",
       "26300       3        0  POLYGON ((3037766.475 13851439.564, 3038034.75...  \n",
       "\n",
       "[26301 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coord_gdf = gpd.read_file('../src/coord/coord_gdf.shp')\n",
    "coord_gdf = coord_gdf.drop(columns=['cell_rmse1', 'cell_r21', 'cell_rmse2', 'cell_r22', 'depth'])\n",
    "coord_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cypress Creek': 0,\n",
       " 'Greens Bayou': 1,\n",
       " 'Whiteoak Bayou-Buffalo Bayou': 2,\n",
       " 'Addicks Reservoir': 3,\n",
       " 'Barker Reservoir': 4,\n",
       " 'Hunting Bayou': 5,\n",
       " 'Vince Bayou-Buffalo Bayou': 6,\n",
       " 'Brays Bayou': 7,\n",
       " 'Sims Bayou': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watershed_dict = coord_gdf.drop_duplicates(subset='HUC12').set_index('HUC12')['region'].to_dict()\n",
    "watershed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "xy_scaled = scaler.fit_transform(coord_gdf[['x', 'y']])\n",
    "\n",
    "def load_and_scale(file_path, scale=False):\n",
    "    df = pd.read_parquet(file_path)[['x', 'y', 'channel', 'ter', 'cumu_rain', 'peak_int', 'duration', 'depth']]\n",
    "    if scale:\n",
    "        df[['x', 'y']] = xy_scaled\n",
    "    return df\n",
    "\n",
    "file_paths = [f'../src/tables/data{i}.parquet' for i in range(1, len([f for f in os.listdir('../src/tables') if f.endswith('.parquet')]) + 1)]\n",
    "events = [load_and_scale(file) for file in file_paths]\n",
    "with ProgressBar():\n",
    "    result = dpd.concat(events, axis=0)\n",
    "events_df = result.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>channel</th>\n",
       "      <th>ter</th>\n",
       "      <th>cumu_rain</th>\n",
       "      <th>peak_int</th>\n",
       "      <th>duration</th>\n",
       "      <th>depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.933766e+06</td>\n",
       "      <td>1.396557e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>301.388702</td>\n",
       "      <td>3.001601</td>\n",
       "      <td>3.001601</td>\n",
       "      <td>1</td>\n",
       "      <td>3.866364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.934966e+06</td>\n",
       "      <td>1.396557e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>301.594696</td>\n",
       "      <td>3.127318</td>\n",
       "      <td>3.127318</td>\n",
       "      <td>1</td>\n",
       "      <td>2.150513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.933766e+06</td>\n",
       "      <td>1.396437e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>294.629181</td>\n",
       "      <td>3.211096</td>\n",
       "      <td>3.211096</td>\n",
       "      <td>1</td>\n",
       "      <td>3.595856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.934966e+06</td>\n",
       "      <td>1.396437e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>298.529877</td>\n",
       "      <td>3.260372</td>\n",
       "      <td>3.260372</td>\n",
       "      <td>1</td>\n",
       "      <td>2.782227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.936166e+06</td>\n",
       "      <td>1.396437e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>294.815002</td>\n",
       "      <td>3.309647</td>\n",
       "      <td>3.309647</td>\n",
       "      <td>1</td>\n",
       "      <td>2.787598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26296</th>\n",
       "      <td>3.039069e+06</td>\n",
       "      <td>1.385008e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>54.643570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26297</th>\n",
       "      <td>3.039053e+06</td>\n",
       "      <td>1.385088e+07</td>\n",
       "      <td>1</td>\n",
       "      <td>59.625050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26298</th>\n",
       "      <td>3.038396e+06</td>\n",
       "      <td>1.385006e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>60.055576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26299</th>\n",
       "      <td>3.038392e+06</td>\n",
       "      <td>1.385087e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>59.625050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26300</th>\n",
       "      <td>3.037707e+06</td>\n",
       "      <td>1.385085e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>72.228638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15570192 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  x             y  channel         ter  cumu_rain  peak_int  \\\n",
       "0      2.933766e+06  1.396557e+07        0  301.388702   3.001601  3.001601   \n",
       "1      2.934966e+06  1.396557e+07        0  301.594696   3.127318  3.127318   \n",
       "2      2.933766e+06  1.396437e+07        0  294.629181   3.211096  3.211096   \n",
       "3      2.934966e+06  1.396437e+07        0  298.529877   3.260372  3.260372   \n",
       "4      2.936166e+06  1.396437e+07        0  294.815002   3.309647  3.309647   \n",
       "...             ...           ...      ...         ...        ...       ...   \n",
       "26296  3.039069e+06  1.385008e+07        1   54.643570   0.000000  0.000000   \n",
       "26297  3.039053e+06  1.385088e+07        1   59.625050   0.000000  0.000000   \n",
       "26298  3.038396e+06  1.385006e+07        0   60.055576   0.000000  0.000000   \n",
       "26299  3.038392e+06  1.385087e+07        0   59.625050   0.000000  0.000000   \n",
       "26300  3.037707e+06  1.385085e+07        0   72.228638   0.000000  0.000000   \n",
       "\n",
       "       duration     depth  \n",
       "0             1  3.866364  \n",
       "1             1  2.150513  \n",
       "2             1  3.595856  \n",
       "3             1  2.782227  \n",
       "4             1  2.787598  \n",
       "...         ...       ...  \n",
       "26296         2  0.000000  \n",
       "26297         2  0.000000  \n",
       "26298         2  0.000000  \n",
       "26299         2  0.000000  \n",
       "26300         2  0.000000  \n",
       "\n",
       "[15570192 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(events_df, test_size=0.4, random_state=0)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_scale = np.array([32.92088739, 27.089618  , 32])\n",
    "feature_cols = ['cumu_rain', 'peak_int', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_index(idx, events_df, feature_cols, feats_scale=[]):\n",
    "    # Select rows corresponding to the current index and extract relevant columns\n",
    "    array_2d = events_df.loc[events_df.index == idx, feature_cols].values \n",
    "    if len(feats_scale) > 0:\n",
    "        array_2d /= feats_scale\n",
    "    return array_2d\n",
    "\n",
    "def df_to_list_of_2d_arrays(events_df, feature_cols, feats_scale=[]):\n",
    "    # Get unique indices\n",
    "    unique_indices = list(sorted(events_df.index.unique()))\n",
    "\n",
    "    # print(unique_indices == list(range(26301)))\n",
    "\n",
    "    # Initialize an empty list to hold the 2D arrays\n",
    "    arrays_2d = []\n",
    "\n",
    "    # Use a ThreadPoolExecutor to parallelize the processing\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=80) as executor:\n",
    "        # Create a list of futures\n",
    "        futures = [executor.submit(process_index, idx, events_df, feature_cols, feats_scale) for idx in unique_indices]\n",
    "        \n",
    "        # Iterate over the futures with a progress bar\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc='Processing'):\n",
    "            # Append the result to the list of 2D arrays\n",
    "            arrays_2d.append(future.result())\n",
    "\n",
    "    return arrays_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 26301/26301 [00:08<00:00, 2998.87it/s] \n"
     ]
    }
   ],
   "source": [
    "X_test_scaled_list = df_to_list_of_2d_arrays(test_df, feature_cols, feats_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 26301/26301 [00:24<00:00, 1073.55it/s] \n"
     ]
    }
   ],
   "source": [
    "y_test_list = df_to_list_of_2d_arrays(test_df, ['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26301/26301 [02:52<00:00, 152.78it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred_list = []\n",
    "for i in trange(len(X_test_scaled_list)):\n",
    "    xg_reg = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.01,\n",
    "                              max_depth = 5, alpha = 10, n_estimators = 1000, n_jobs=10)\n",
    "    best_checkpoint = f'../checkpoints/depth/MaxFloodCast1/XGBOOST_{i}.mod'\n",
    "    xg_reg.load_model(best_checkpoint)\n",
    "    predictions = xg_reg.predict(X_test_scaled_list[i][:, 0:2])\n",
    "    y_pred_list.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rmse(y_true_list, y_pred_list, indices=[]):\n",
    "    rmse_list = []\n",
    "    for i in trange(len(y_true_list), desc='Calc RMSE'):\n",
    "        y_trues = y_true_list[i]\n",
    "        y_preds = y_pred_list[i]\n",
    "        rmse = np.sqrt(np.mean((y_preds - y_trues) ** 2))\n",
    "        if i in indices or len(indices)==0:\n",
    "            rmse_list.append(rmse)\n",
    "    return np.round(np.mean(rmse_list), 4)\n",
    "\n",
    "def calc_r2(y_true_list, y_pred_list, indices=[]):\n",
    "    r2_list = []\n",
    "    for i in trange(len(y_true_list), desc='Calc R2'):\n",
    "        y_trues = y_true_list[i]\n",
    "        y_preds = y_pred_list[i]\n",
    "        r2 = 1 - (np.sum((y_preds - y_trues)**2))/(np.sum((y_trues - np.mean(y_trues))**2))\n",
    "        if i in indices or len(indices)==0:\n",
    "            r2_list.append(r2)\n",
    "    return np.round(np.mean(r2_list), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calc RMSE: 100%|██████████| 26301/26301 [00:01<00:00, 15954.24it/s]\n",
      "Calc R2: 100%|██████████| 26301/26301 [00:02<00:00, 12559.32it/s]\n"
     ]
    }
   ],
   "source": [
    "test_rmse = calc_rmse(y_test_list, y_pred_list)\n",
    "test_r2 = calc_r2(y_test_list, y_pred_list)\n",
    "test_result_dict = {\n",
    "    'rmse': test_rmse,\n",
    "    'r2': test_r2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_indices = coord_gdf[coord_gdf['channel'] == 1].index\n",
    "non_channel_indices = coord_gdf[coord_gdf['channel'] == 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calc RMSE: 100%|██████████| 26301/26301 [00:01<00:00, 15301.45it/s]\n",
      "Calc R2: 100%|██████████| 26301/26301 [00:02<00:00, 10872.56it/s]\n",
      "Calc RMSE: 100%|██████████| 26301/26301 [00:01<00:00, 15010.56it/s]\n",
      "Calc R2: 100%|██████████| 26301/26301 [00:02<00:00, 12614.26it/s]\n"
     ]
    }
   ],
   "source": [
    "channel_rmse = calc_rmse(y_test_list, y_pred_list, channel_indices)\n",
    "channel_r2 = calc_r2(y_test_list, y_pred_list, channel_indices)\n",
    "non_channel_rmse = calc_rmse(y_test_list, y_pred_list, non_channel_indices)\n",
    "non_channel_r2 = calc_r2(y_test_list, y_pred_list, non_channel_indices)\n",
    "test_result_dict['channel_rmse'] = channel_rmse\n",
    "test_result_dict['channel_r2'] = channel_r2\n",
    "test_result_dict['non_channel_rmse'] = non_channel_rmse\n",
    "test_result_dict['non_channel_r2'] = non_channel_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rmse': 4.6045,\n",
       " 'r2': -891.5814,\n",
       " 'channel_rmse': 9.3247,\n",
       " 'channel_r2': -575.529,\n",
       " 'non_channel_rmse': 4.0002,\n",
       " 'non_channel_r2': -932.0436}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
